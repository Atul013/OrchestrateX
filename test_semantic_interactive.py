#!/usr/bin/env python3
"""
Interactive Semantic Model Selector Tester
Test the intelligent context-aware system with your own prompts
"""

import sys
import os
from semantic_model_selector import SemanticModelSelector

def interactive_semantic_test():
    """Interactive tester for the semantic model selector."""
    
    print("üß† Interactive Semantic Model Selector")
    print("=" * 60)
    print("üéØ This system uses semantic analysis (no hardcoded keywords)")
    print("üí° It understands context, intent, and meaning")
    print("üîç Watch how it analyzes your prompts...")
    print()
    
    # Initialize the semantic selector
    selector = SemanticModelSelector()
    print()
    
    while True:
        # Get user input
        print("üí¨ Enter your prompt (or 'quit' to exit):")
        prompt = input(">>> ").strip()
        
        if prompt.lower() in ['quit', 'exit', 'q']:
            print("üëã Thanks for testing! Goodbye!")
            break
            
        if not prompt:
            print("‚ùå Please enter a prompt!")
            continue
        
        print(f"\nüîç Analyzing: '{prompt}'")
        print("=" * 60)
        
        try:
            # Get semantic analysis
            context = selector.analyze_semantic_context(prompt)
            
            print("üß† **SEMANTIC ANALYSIS:**")
            print(f"  üìä Intent Type: {context['intent_type']}")
            print(f"  üè∑Ô∏è  Domain Signals: {', '.join(context['domain_signals'])}")
            print(f"  üìà Complexity Level: {context['complexity_level']}")
            print(f"  üé≠ Interaction Style: {context['interaction_style']}")
            print(f"  üì§ Expected Output: {context['output_expectation']}")
            print(f"  ü§î Ambiguity Level: {context['ambiguity_level']:.1%}")
            print()
            
            # Get model selection
            model, confidence, reasoning = selector.semantic_model_selection(prompt)
            
            # Display results with emojis
            if confidence >= 0.9:
                confidence_emoji = "üéØ"
                confidence_desc = "VERY HIGH"
            elif confidence >= 0.8:
                confidence_emoji = "‚úÖ"
                confidence_desc = "HIGH"
            elif confidence >= 0.7:
                confidence_emoji = "üìä"
                confidence_desc = "GOOD"
            elif confidence >= 0.6:
                confidence_emoji = "ü§∑"
                confidence_desc = "MEDIUM"
            else:
                confidence_emoji = "‚ö†Ô∏è"
                confidence_desc = "LOW"
            
            print("üéØ **MODEL SELECTION:**")
            print(f"{confidence_emoji} **Selected Model:** {model}")
            print(f"üìä **Confidence:** {confidence:.1%} ({confidence_desc})")
            print(f"üí≠ **Reasoning:** {reasoning}")
            print()
            
            # Show why this model was chosen
            print("üî¨ **WHY THIS MODEL?**")
            if model == 'TNG DeepSeek':
                if 'technical' in context['domain_signals']:
                    print("  ‚Ä¢ Technical implementation detected")
                if context['output_expectation'] == 'code':
                    print("  ‚Ä¢ Code output expected")
                if context['intent_type'] == 'creation':
                    print("  ‚Ä¢ Creation/building task identified")
            
            elif model == 'GLM4.5':
                if context['intent_type'] == 'analysis':
                    print("  ‚Ä¢ Analytical reasoning required")
                if 'business' in context['domain_signals']:
                    print("  ‚Ä¢ Business/professional context")
                if context['complexity_level'] in ['complex', 'very_complex']:
                    print("  ‚Ä¢ Complex reasoning needed")
            
            elif model == 'Llama 4 Maverick':
                if context['intent_type'] == 'inquiry':
                    print("  ‚Ä¢ Educational question format")
                if 'educational' in context['domain_signals']:
                    print("  ‚Ä¢ Learning-oriented request")
                if context['output_expectation'] == 'explanation':
                    print("  ‚Ä¢ Explanatory response needed")
            
            elif model == 'GPT-OSS':
                if 'cultural' in context['domain_signals']:
                    print("  ‚Ä¢ Cultural/general knowledge")
                if 'creative' in context['domain_signals']:
                    print("  ‚Ä¢ Creative content creation")
                if context['intent_type'] == 'general':
                    print("  ‚Ä¢ General purpose best fit")
            
            elif model == 'Qwen3':
                if context['intent_type'] == 'analysis':
                    print("  ‚Ä¢ Logical reasoning required")
                print("  ‚Ä¢ Precision and structured thinking")
            
            elif model == 'MoonshotAI Kimi':
                if context['interaction_style'] == 'assistance':
                    print("  ‚Ä¢ Personal assistance request")
                print("  ‚Ä¢ Conversational and practical guidance")
            
        except Exception as e:
            print(f"‚ùå Error analyzing prompt: {e}")
            continue
        
        print("\n" + "=" * 60 + "\n")

if __name__ == "__main__":
    interactive_semantic_test()
